---
title: "BCF_nonlinear"
author: "Shiqi Wang"
date: "4/26/2025"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load libraries
library(bcf)
library(dplyr)
library(Metrics)

```

```{r}
start_time <- Sys.time()
# -----------------------------
# 1. Data generation function
# -----------------------------
generate_data <- function(n, hetero_effect, nonlinear_prognostic) {
  x1 <- rnorm(n)
  x2 <- rnorm(n)
  x3 <- rnorm(n)
  x4 <- sample(0:1, n, replace = TRUE)
  x5 <- sample(1:3, n, replace = TRUE)
  
  # Treatment effect
  tau <- if (!hetero_effect) {
    rep(3, n)
  } else {
    1 + 2 * x2 * x4
  }
  
  # Prognostic function
  g <- c(`1` = 2, `2` = -1, `3` = -4)
  if (!nonlinear_prognostic) {
    mu <- 1 + g[as.character(x5)] + x1 * x3
  } else {
    mu <- -6 + g[as.character(x5)] + 6 * abs(x3 - 1)
  }
  
  # Propensity score
  s <- sd(mu)
  pi <- 0.8 * pnorm((3 * mu) / s - 0.5 * x1) + 0.05 + runif(n, 0, 0.1)
  
  # Treatment assignment
  Z <- rbinom(n, 1, pi)
  
  # Outcome variable
  Y <- mu + tau * Z + rnorm(n)
  
  # Return dataframe
  data.frame(x1, x2, x3, x4, x5, tau, mu, pi, Z, Y)
}

# -----------------------------
# 2. Simulation settings
# -----------------------------
num_rep <- 1  # 50 repetitions
n <- 250       # sample size
hetero_effect <- TRUE         # TRUE = heterogeneous effect
nonlinear_prognostic <- TRUE  # FALSE = linear prognostic

# Storage for results
results_list <- list()

# -----------------------------
# 3. Simulation loop
# -----------------------------
for (i in 1:num_rep) {
  
  set.seed(123 + i)  # different seed for each repetition
  
  # --- Generate data ---
  data <- generate_data(n = n, hetero_effect = hetero_effect, nonlinear_prognostic = nonlinear_prognostic)
  
  # --- Prepare variables for BCF ---
  x <- data %>% select(x1, x2, x3, x4, x5) %>% as.matrix()
  y <- data$Y
  z <- data$Z
  pihat <- data$pi
  true_tau <- data$tau
  
  # --- Fit BCF model ---
  fit <- bcf(
    y = y,
    z = z,
    x_control = x,
    x_moderate = x,
    pihat = pihat,
    nburn = 1000,   # lighter for testing
    nsim = 1000,
    ntree_control = 200,  # number of trees for μ(x)
    ntree_moderate = 50   # number of trees for τ(x)
  )
  
  # --- Posterior processing ---
  tau_post <- fit$tau
  tauhat <- colMeans(tau_post)
  
  # --- Credible intervals ---
  tau_lower <- apply(tau_post, 2, quantile, probs = 0.025)
  tau_upper <- apply(tau_post, 2, quantile, probs = 0.975)
  
  # --- Metrics for CATE ---
  cate_rmse <- rmse(true_tau, tauhat)
  cate_cover <- mean(true_tau >= tau_lower & true_tau <= tau_upper)
  cate_len <- mean(tau_upper - tau_lower)
  
  # --- Metrics for ATE ---
  ate_true <- mean(true_tau)
  ate_estimate <- mean(tauhat)
  ate_rmse <- sqrt((ate_estimate - ate_true)^2)
  
  ate_lower <- quantile(rowMeans(tau_post), 0.025)
  ate_upper <- quantile(rowMeans(tau_post), 0.975)
  
  ate_cover <- as.numeric(ate_true >= ate_lower & ate_true <= ate_upper)
  ate_len <- ate_upper - ate_lower
  
  # --- Store results ---
  results_list[[i]] <- tibble(
    rep = i,
    ate_rmse = ate_rmse,
    ate_cover = ate_cover,
    ate_len = ate_len,
    cate_rmse = cate_rmse,
    cate_cover = cate_cover,
    cate_len = cate_len
  )
}

# -----------------------------
# 4. Summarize final results
# -----------------------------
results_df <- bind_rows(results_list)

summary_results <- results_df %>%
  summarise(
    ate_rmse = mean(ate_rmse, na.rm = TRUE),
    ate_cover = mean(ate_cover, na.rm = TRUE),
    ate_len = mean(ate_len, na.rm = TRUE),
    cate_rmse = mean(cate_rmse, na.rm = TRUE),
    cate_cover = mean(cate_cover, na.rm = TRUE),
    cate_len = mean(cate_len, na.rm = TRUE)
  )

# Print final summarized results
print(summary_results)
end_time <- Sys.time()

# Calculate the time difference
time_taken <- end_time - start_time
print(time_taken)
```

